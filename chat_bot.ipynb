{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, RepeatVector, TimeDistributed, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "print(\"Libraries loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(\"train_qa.csv\")\n",
    "test_df = pd.read_csv(\"test_qa.csv\")\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary and Preprocessing\n",
    "vocab = set()\n",
    "\n",
    "train_df[\"story\"] = train_df[\"story\"].astype(str)\n",
    "train_df[\"question\"] = train_df[\"question\"].astype(str)\n",
    "train_df[\"answer\"] = train_df[\"answer\"].astype(str)\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    vocab.update(row[\"story\"].split())\n",
    "    vocab.update(row[\"question\"].split())\n",
    "\n",
    "vocab.update([\"yes\", \"no\"])\n",
    "vocab_len = len(vocab)\n",
    "print(\" Vocabulary size:\", vocab_len)\n",
    "\n",
    "#Tokenization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(list(train_df[\"story\"]) + list(train_df[\"question\"]))\n",
    "\n",
    "story_maxlen = max([len(s.split()) for s in train_df[\"story\"]])\n",
    "question_maxlen = max([len(q.split()) for q in train_df[\"question\"]])\n",
    "\n",
    "def vectorize_data(dataframe, tokenizer, story_maxlen, question_maxlen):\n",
    "    Xstories, Xquestions, Yanswers = [], [], []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        s_seq = tokenizer.texts_to_sequences([row[\"story\"].lower()])[0]\n",
    "        q_seq = tokenizer.texts_to_sequences([row[\"question\"].lower()])[0]\n",
    "        ans = 1 if row[\"answer\"].strip().lower() == \"yes\" else 0\n",
    "        Xstories.append(s_seq)\n",
    "        Xquestions.append(q_seq)\n",
    "        Yanswers.append(ans)\n",
    "    Xstories = pad_sequences(Xstories, maxlen=story_maxlen)\n",
    "    Xquestions = pad_sequences(Xquestions, maxlen=question_maxlen)\n",
    "    Yanswers = np.array(Yanswers)\n",
    "    return Xstories, Xquestions, Yanswers\n",
    "\n",
    "Xstory, Xques, Y = vectorize_data(train_df, tokenizer, story_maxlen, question_maxlen)\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain_story, Xval_story, Xtrain_ques, Xval_ques, Ytrain, Yval = train_test_split(\n",
    "    Xstory, Xques, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embed_size = 128\n",
    "story_input = Input((story_maxlen,))\n",
    "question_input = Input((question_maxlen,))\n",
    "\n",
    "story_encoder = Embedding(vocab_len + 1, embed_size)(story_input)\n",
    "story_encoder = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(story_encoder)\n",
    "story_encoder = LSTM(64, activation='tanh')(story_encoder)\n",
    "\n",
    "question_encoder = Embedding(vocab_len + 1, embed_size)(question_input)\n",
    "question_encoder = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(question_encoder)\n",
    "question_encoder = LSTM(64, activation='tanh')(question_encoder)\n",
    "\n",
    "merged = concatenate([story_encoder, question_encoder])\n",
    "merged = Dense(32, activation='relu')(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([story_input, question_input], output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"chatbot_model_best.h5\", monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    [Xtrain_story, Xtrain_ques], Ytrain,\n",
    "    validation_data=([Xval_story, Xval_ques], Yval),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "Xtest_story, Xtest_ques, Ytest = vectorize_data(test_df, tokenizer, story_maxlen, question_maxlen)\n",
    "test_loss, test_acc = model.evaluate([Xtest_story, Xtest_ques], Ytest)\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(f\"Test Loss: {test_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be09e5d",
   "metadata": {},
   "source": [
    "## Step 4: Test or Interact with the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf1632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chatbot_response(story, question):\n",
    "    model = tf.keras.models.load_model(\"chatbot_model.h5\")\n",
    "    s_seq = tokenizer.texts_to_sequences([story])\n",
    "    q_seq = tokenizer.texts_to_sequences([question])\n",
    "    s_pad = pad_sequences(s_seq, maxlen=story_maxlen)\n",
    "    q_pad = pad_sequences(q_seq, maxlen=question_maxlen)\n",
    "    pred = model.predict([s_pad, q_pad])[0][0]\n",
    "    return \"yes\" if pred > 0.5 else \"no\"\n",
    "\n",
    "story_input = \"Sandra got the football there. Mary went to the bedroom.\"\n",
    "question_input = \"Is Mary in the bedroom?\"\n",
    "print(\"Chatbot answer:\", chatbot_response(story_input, question_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_qa(story, question, answer, csv_file=\"train_qa.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    new_entry = {\"story\": story, \"question\": question, \"answer\": answer}\n",
    "    df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\" Added new QA to {csv_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
